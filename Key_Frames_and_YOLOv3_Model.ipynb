{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarisudhanVL/Key-Frames-Extraction-and-Object-Detection/blob/main/Key_Frames_and_YOLOv3_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH68FtbfjU_g"
      },
      "source": [
        "## Extraction of keyframes from a video using pyhton."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IckJoqFjjU_l"
      },
      "source": [
        "### Required libraries for extracting keyframes from a video."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Katna is a Python library that automates the boring, error-prone task of video keyframe extraction, video compression, and image cropping and resizing. It is a free and open-source library**"
      ],
      "metadata": {
        "id": "9dQcmRtXkABC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3agwTqwjU_m"
      },
      "outputs": [],
      "source": [
        "from Katna.video import Video\n",
        "from Katna.writer import KeyFrameDiskWriter\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLENb8KHjU_p"
      },
      "source": [
        "### Extraction of keyframes from a video.\n",
        "\n",
        "**Katna uses a variety of techniques to extract keyframes, including:**\n",
        "\n",
        "***Motion detection: This technique identifies frames that contain significant motion.***\n",
        "\n",
        "**Face detection: This technique identifies frames that contain faces**.\n",
        "\n",
        "***Saliency detection: This technique identifies frames that are visually salient.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW196u3ijU_q",
        "outputId": "78f87fdd-ca6f-4c6e-b43f-997c5d139c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input video file path = D:\\Tann Mann Intership\\Interview task\\video.mp4\n",
            "Completed processing for :  D:\\Tann Mann Intership\\Interview task\\video.mp4\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    vd = Video()\n",
        "    no_of_frames_to_returned = 12\n",
        "    diskwriter = KeyFrameDiskWriter(location=r\"D:\\Tann Mann Intership\\Interview task\\KeyFrames\") ## Saving the frames locally.\n",
        "    video_file_path = os.path.join(\".\", \"tests\", \"data\", \"D:\\Tann Mann Intership\\Interview task\\\\video.mp4\") ## Input video.\n",
        "    print(f\"Input video file path = {video_file_path}\")\n",
        "    vd.extract_video_keyframes(no_of_frames=no_of_frames_to_returned, file_path=video_file_path, writer=diskwriter) ## Extracting Keyframes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ymbcbljU_t"
      },
      "source": [
        "## Detecting objects from the detected keyframes using YOLOv3 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkcjbO5MjU_u"
      },
      "source": [
        "### Required libraries for building YOLOv3 Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0z94ojzjU_u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i65OR6ngjU_v"
      },
      "source": [
        "### Change the working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36NNqdg0jU_w"
      },
      "outputs": [],
      "source": [
        "os.chdir(r\"D:\\Tann Mann Intership\\Interview task\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObntJt0rjU_x"
      },
      "source": [
        "### Load YOLOv3 model's weights, configuration and classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLDVgWWDjU_y"
      },
      "outputs": [],
      "source": [
        "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"coco.names\",\"r\") as f:\n",
        "    classes = f.read().splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQw086zLjU_y"
      },
      "source": [
        "### Pre-trained model classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORPkCDYEjU_z",
        "outputId": "60498276-c70c-40d7-a24e-dc0a64193de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ]
        }
      ],
      "source": [
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEcEitFVjU_0",
        "outputId": "f125ca36-43fc-4030-cdd4-354876d38954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of objects = 5\n",
            "Number of objects = 5\n",
            "Number of objects = 1\n",
            "Number of objects = 3\n",
            "Number of objects = 3\n",
            "Number of objects = 2\n",
            "Number of objects = 3\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,12):\n",
        "    # Loading_keyframes\n",
        "    img = cv2.imread(r\"D:\\Tann Mann Intership\\Interview task\\KeyFrames\\video_%d.jpeg\" %i)\n",
        "    height,width,_ = img.shape\n",
        "\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(img,1/255,(416,416),(0,0,0),swapRB=True,crop = False)\n",
        "\n",
        "    #for b in blob:\n",
        "     #   for n,img_blob in enumerate(b):\n",
        "      #      cv2.imshow(str(n),img_blob)\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Output layers\n",
        "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
        "    layerOutputs = net.forward(output_layers_names)\n",
        "\n",
        "    # Showing info on screen / get confidence score of algorithm in detecting an object in blob\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0]*width)\n",
        "                center_y = int(detection[1]*height)\n",
        "                w = int(detection[2]*width)\n",
        "                h = int(detection[3]*height)\n",
        "\n",
        "                x = int(center_x - w/2)\n",
        "                y = int(center_y - h/2)\n",
        "\n",
        "                boxes.append([x,y,w,h])\n",
        "                confidences.append((float(confidence)))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
        "\n",
        "    # Drawing box over the detected object.\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    colors = np.random.uniform(0,255,size=(len(boxes),3))\n",
        "\n",
        "    lists=[]\n",
        "    j=0\n",
        "    if len(indexes) > 0:\n",
        "        for i in indexes.flatten():\n",
        "            x,y,w,h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = str(round(confidences[i],2))\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(img,(x,y),(x+w, y+h),color,2)\n",
        "            cv2.putText(img,label+\" \"+confidence, (x,y+20),font,2,(255,255,255),2)\n",
        "\n",
        "            cv2.imshow(\"Image\",img)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "            j+=1\n",
        "        print(\"Number of objects = %d\" %(j))\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}